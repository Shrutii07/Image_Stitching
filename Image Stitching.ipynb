{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris\n",
    "def panaroma_rsd(img_rsd1,img_rsd2):\n",
    "    \n",
    "    def stitch_rsd(input_img_rsd1, input_img_rsd2):\n",
    "        \n",
    "        def corner_rsd(input_img_rsd, b_size = 9, k_size=3, alpha = 0.04):\n",
    "            # inputs: \n",
    "            # input_img_rsd: input grayscale image\n",
    "            # b_size: block_size for Gaussian filter\n",
    "            # k_size: k_size for sobel i.e. sobel window size\n",
    "            # alpha: constant in R \n",
    "            # for a grayscale image finds harris corner\n",
    "            h, w = input_img_rsd.shape[0],input_img_rsd.shape[1]\n",
    "            \n",
    "            # derivatives using sobel operator\n",
    "            der_x = cv2.Sobel(input_img_rsd,cv2.CV_64F,1,0,ksize=k_size)\n",
    "            der_y = cv2.Sobel(input_img_rsd,cv2.CV_64F,0,1,ksize=k_size)\n",
    "\n",
    "            # 2nd moment matrix generation\n",
    "            Ixx=der_x*der_x\n",
    "            Ixy=der_x*der_y\n",
    "            Iyy=der_y*der_y\n",
    "            \n",
    "            # gaussian kernel size is given by ip b_size\n",
    "\n",
    "            # Moment matrix M = summation of W(x,y)[[Ix^2 ,IxIy],[IxIy,Iy^2]]\n",
    "            Ixx = cv2.GaussianBlur(Ixx,(b_size,b_size),0)\n",
    "            Ixy = cv2.GaussianBlur(Ixy,(b_size,b_size),0)\n",
    "            Iyy = cv2.GaussianBlur(Iyy,(b_size,b_size),0)\n",
    "            # r matrix\n",
    "            r_mat=np.zeros([h,w],dtype=float)\n",
    "            for i in range(0,h):\n",
    "                    for j in range(0,w):\n",
    "                        M = [[Ixx[i,j],Ixy[i,j]],[Ixy[i,j],Iyy[i,j]]]\n",
    "\n",
    "                        r_mat[i][j] = np.linalg.det(M) - alpha*(np.trace(M)**2)\n",
    "\n",
    "            # threshold = 10% Rmax\n",
    "            threshold= 0.01*np.max(r_mat)   \n",
    "            corners_rsd=[]\n",
    "            for i in range(h):\n",
    "                for j in range(w):\n",
    "                    if r_mat[i][j] >= threshold:\n",
    "                        corners_rsd.append([i,j]) \n",
    "            # returns list with corners coordinates\n",
    "            return corners_rsd\n",
    "\n",
    "\n",
    "        def reshape_rsd(image):\n",
    "            \n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # apply binary threshold to grayscale img\n",
    "            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "            # Finds contours from the binary image\n",
    "            _,cnts,_ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnt = cnts[0]\n",
    "            \n",
    "            # boundary elements are found\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            # crop the image to the bbox coordinates\n",
    "            result = image[y:y + h, x:x + w]\n",
    "        \n",
    "            return result\n",
    "  \n",
    "        # create SIFT object\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "        \n",
    "        # for 3d image convert img, convert it to grayscale first \n",
    "        if input_img_rsd1.ndim == 3 & input_img_rsd2.ndim == 3:\n",
    "            input_img_rsd1_gray = cv2.cvtColor(input_img_rsd1, cv2.COLOR_BGR2GRAY)\n",
    "            input_img_rsd2_gray = cv2.cvtColor(input_img_rsd2, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # calling harris corner function to detect keypoints\n",
    "            coordinatesA =  corner_rsd(input_img_rsd1_gray,3,3,0.04)\n",
    "            coordinatesB =  corner_rsd(input_img_rsd2_gray,3,3,0.04)\n",
    "\n",
    "        else:\n",
    "            coordinatesA  =  corner_rsd(input_img_rsd1,3,3,0.04)\n",
    "            coordinatesB =  corner_rsd(input_img_rsd2,3,3,0.04)\n",
    "        \n",
    "        key_pointsA=[]\n",
    "        key_pointsB=[]\n",
    "        # converting list of coordinates to keypoints\n",
    "        for p in coordinatesA:\n",
    "            key_pointsA.append(cv2.KeyPoint(float(p[1]),float(p[0]),10))\n",
    "\n",
    "        for p in coordinatesB:\n",
    "            key_pointsB.append(cv2.KeyPoint(float(p[1]),float(p[0]),10))\n",
    "            \n",
    "            \n",
    "        # computing descriptors and features for custom keypoints\n",
    "        (featuresA, descriptorsA) = descriptor.compute(input_img_rsd1,key_pointsA)\n",
    "\n",
    "        (featuresB, descriptorsB) = descriptor.compute(input_img_rsd2,key_pointsB)\n",
    "        \n",
    "        # Brute force matcher\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n",
    "        \n",
    "        # matching descriptors\n",
    "        best_matches = bf.match(descriptorsA, descriptorsB)\n",
    "        \n",
    "        # sorting matches based on distance\n",
    "        Matches_rsd = sorted(best_matches, key = lambda x:x.distance)\n",
    "\n",
    "        #img3 = cv2.drawMatches(input_img_rsd1,featuresA,input_img_rsd2,featuresB, Matches_rsd[:100],\n",
    "                                   #None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "        kpsA = np.float32([kp.pt for kp in featuresA])\n",
    "        kpsB = np.float32([kp.pt for kp in featuresB])\n",
    "\n",
    "        if len( Matches_rsd ) > 4:\n",
    "\n",
    "                # construct the two sets of points\n",
    "                ptsA = np.float32([kpsA[m.queryIdx] for m in  Matches_rsd ])\n",
    "                ptsB = np.float32([kpsB[m.trainIdx] for m in  Matches_rsd ])\n",
    "\n",
    "                # estimate the homography between the sets of points\n",
    "                (H, status) = cv2.findHomography(ptsB, ptsA, cv2.RANSAC,4)\n",
    "        \n",
    "        # H_inv\n",
    "        xh = np.linalg.inv(H)\n",
    "        # compensating negative translation \n",
    "        f1 = np.dot(xh, np.array([0,0,1]))\n",
    "        f1 = f1/f1[-1]\n",
    "        xh[0][-1] += abs(f1[0])\n",
    "        xh[1][-1] += abs(f1[1])\n",
    "        # determining offset for img\n",
    "        ds = np.dot(xh, np.array([input_img_rsd1.shape[1], input_img_rsd1.shape[0], 1]))\n",
    "        offsety = abs(int(f1[1]))\n",
    "        offsetx = abs(int(f1[0]))\n",
    "        dsize = (int(ds[0])+offsetx+input_img_rsd2.shape[0], int(ds[1]) + offsety+input_img_rsd2.shape[1])\n",
    "\n",
    "        # wrap first img wrt second\n",
    "        output_rsd = cv2.warpPerspective(input_img_rsd1, xh, dsize)\n",
    "        # second imag added\n",
    "        output_rsd[offsety:input_img_rsd2.shape[0]+offsety, offsetx:input_img_rsd2.shape[1]+offsetx] = input_img_rsd2\n",
    "        \n",
    "        # resizing image\n",
    "        output_image_rsd = reshape_rsd(output_rsd)\n",
    "        \n",
    "        return output_image_rsd \n",
    "    \n",
    "    try:\n",
    "        # right stitch\n",
    "        result=stitch_rsd(img_rsd1,img_rsd2)\n",
    "    except:\n",
    "        # left stitch\n",
    "        result=stitch_rsd(img_rsd2,img_rsd1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT\n",
    "def image_stitch_rsd(img_rsd1,img_rsd2):\n",
    "    \n",
    "    def stitch_rsd(input_img_rsd1,input_img_rsd2):\n",
    "    \n",
    "        def reshape_rsd(image):\n",
    "            \n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # apply binary threshold to grayscale img\n",
    "            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "            # Finds contours from the binary image\n",
    "            _,cnts,_ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnt = cnts[0]\n",
    "            \n",
    "            # boundary elements are found\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            # crop the image to the bbox coordinates\n",
    "            result = image[y:y + h, x:x + w]\n",
    "        \n",
    "            return result\n",
    "\n",
    "         # create SIFT object\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "        \n",
    "         #calculating features and descriptors using SIFT\n",
    "        (featuresA, descriptorsA) = descriptor.detectAndCompute(input_img_rsd1, None)\n",
    "        (featuresB, descriptorsB) = descriptor.detectAndCompute(input_img_rsd2, None)\n",
    "\n",
    "        # Brute force matcher\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n",
    "        \n",
    "        # matching descriptors\n",
    "        best_matches = bf.match(descriptorsA, descriptorsB)\n",
    "        \n",
    "        # sorting matches based on distance\n",
    "        Matches_rsd = sorted(best_matches, key = lambda x:x.distance)\n",
    "\n",
    "        #img3 = cv2.drawMatches(input_img_rsd1,featuresA,input_img_rsd2,featuresB, Matches_rsd[:100],\n",
    "                                   #None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "        kpsA = np.float32([kp.pt for kp in featuresA])\n",
    "        kpsB = np.float32([kp.pt for kp in featuresB])\n",
    "\n",
    "        if len( Matches_rsd ) > 4:\n",
    "\n",
    "                # construct the two sets of points\n",
    "                ptsA = np.float32([kpsA[m.queryIdx] for m in  Matches_rsd ])\n",
    "                ptsB = np.float32([kpsB[m.trainIdx] for m in  Matches_rsd ])\n",
    "\n",
    "                # estimate the homography between the sets of points\n",
    "                (H, status) = cv2.findHomography(ptsB, ptsA, cv2.RANSAC,4)\n",
    "        \n",
    "        # H_inv\n",
    "        xh = np.linalg.inv(H)\n",
    "        # compensating negative translation \n",
    "        f1 = np.dot(xh, np.array([0,0,1]))\n",
    "        f1 = f1/f1[-1]\n",
    "        xh[0][-1] += abs(f1[0])\n",
    "        xh[1][-1] += abs(f1[1])\n",
    "        # determining offset for img\n",
    "        ds = np.dot(xh, np.array([input_img_rsd1.shape[1], input_img_rsd1.shape[0], 1]))\n",
    "        offsety = abs(int(f1[1]))\n",
    "        offsetx = abs(int(f1[0]))\n",
    "        dsize = (int(ds[0])+offsetx+input_img_rsd2.shape[0], int(ds[1]) + offsety+input_img_rsd2.shape[1])\n",
    "\n",
    "        # wrap first img wrt second\n",
    "        output_rsd = cv2.warpPerspective(input_img_rsd1, xh, dsize)\n",
    "        # second imag added\n",
    "        output_rsd[offsety:input_img_rsd2.shape[0]+offsety, offsetx:input_img_rsd2.shape[1]+offsetx] = input_img_rsd2\n",
    "        \n",
    "        # resizing image\n",
    "        output_image_rsd = reshape_rsd(output_rsd)\n",
    "        \n",
    "        return output_image_rsd \n",
    "    \n",
    "    try:\n",
    "        # right stitch\n",
    "        result=stitch_rsd(img_rsd1,img_rsd2)\n",
    "    except:\n",
    "        # left stitch\n",
    "        result=stitch_rsd(img_rsd2,img_rsd1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random order of sequence\n",
    "\n",
    "def random_rsd(image_list, sequence = int(0), sift = int(1)):\n",
    "    \n",
    "    ## inputs:\n",
    "    ## image_list: list of images\n",
    "    ## sequence = 1 indicates given images are given in sequence\n",
    "    ## sift = 1 indicates output needed using sift algo\n",
    "    ## sift = 0 indicates op needed using harris corner algo\n",
    "    \n",
    "    def matches_rsd(img_1, img_2):\n",
    "        # function that gives no. of matches\n",
    "        \n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "        (featureA, descriptorsA) = descriptor.detectAndCompute(img_1, None)\n",
    "        (featureB, descriptorsB) = descriptor.detectAndCompute(img_2, None)\n",
    "\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n",
    "\n",
    "        best_matches = bf.match(descriptorsA, descriptorsB)\n",
    "\n",
    "        Matches_rsd = sorted(best_matches, key = lambda x:x.distance)\n",
    "\n",
    "        return len(Matches_rsd)\n",
    "   \n",
    "    def stitch_rand_rsd(images_list, sift):\n",
    "        # considering 1 img initially\n",
    "        img1 = images_list[0]\n",
    "        M = []\n",
    "        new_images_list = []\n",
    "        for i in range(1, len(images_list)):\n",
    "            # find matches\n",
    "            value =  matches_rsd(img1, images_list[i])\n",
    "            M.append([value,i])\n",
    "       \n",
    "        # find max no. of matches between img1 and some image\n",
    "        Maxim = max(M)\n",
    "        if sift:    \n",
    "            # op using sift\n",
    "            output = image_stitch_rsd(img1, images_list[Maxim[1]])\n",
    "        else:\n",
    "            # op using harris\n",
    "            output = panaroma_rsd(img1, images_list[Maxim[1]])\n",
    "        L =[output] \n",
    "        \n",
    "        # pop out the 2 used images\n",
    "        images_list.pop(Maxim[1])\n",
    "        images_list.pop(0)\n",
    "        \n",
    "        # append the new stitched img\n",
    "        new_images_list = L + images_list\n",
    "        \n",
    "        # returns new img ist with 1st img as stitched img and remaining imgs\n",
    "        return new_images_list\n",
    "    \n",
    "    ## if sequence is given and sift op is needed\n",
    "    if sequence & sift:\n",
    "        for i in range(len(image_list)-1):\n",
    "            output = image_stitch_rsd(image_list[i], image_list[i+1])\n",
    "            image_list[i+1] = output        \n",
    "        return output\n",
    "    \n",
    "    ## if sequence is given and harris op is needed\n",
    "    elif sequence & ~(sift):\n",
    "        for i in range(len(image_list)-1):\n",
    "            output = panaroma_rsd(image_list[i], image_list[i+1])\n",
    "            image_list[i+1] = output\n",
    "        return output\n",
    "    \n",
    "    # if random sequence is given\n",
    "    else:\n",
    "        while len(image_list) > 1:\n",
    "            image_list = stitch_rand_rsd(image_list, sift)\n",
    "        return image_list[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"m1.jpg\")\n",
    "img2 = cv2.imread(\"m2.jpg\")\n",
    "img3 = cv2.imread(\"m3.jpg\")\n",
    "img4 = cv2.imread(\"m4.jpg\")\n",
    "img5 = cv2.imread(\"m5.jpg\")\n",
    "\n",
    "images = [img1, img2, img3]\n",
    "\n",
    "seq = int(1)\n",
    "sift = int(1)\n",
    "final =  random_rsd(images, seq, sift)\n",
    "\n",
    "cv2.imshow(\"Wrap result\", final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
